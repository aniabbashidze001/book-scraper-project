# ðŸ“š Book Scraper Project

This is a web scraping application which collects data from [BooksToScrape](http://books.toscrape.com), processes the HTML content, extracts structured product data, and saves it into both CSV and JSON formats.

## âœ… Features

- Collects product info: title, price, availability, rating, URL
- Scrapes multiple pages with pagination
- Uses Object-Oriented Programming (OOP)
- Cleans, stores, and reloads structured data
- Performs basic analysis (e.g. count of expensive books)
- Modular Python package structure

## ðŸ”§ Setup Instructions

### 1. Clone the repo:
```bash
git clone https://github.com/YOUR-TEAM/book-scraper-project.git
cd book-scraper-project
```

### 2. Install requirements:
```bash
pip install -r requirements.txt
```

### 3. Run the scraper:
```bash
python main.py
```

Outputs will be saved to the `data/` directory as:
- `books.csv`
- `books.json`

## ðŸ“‚ Project Structure

```
project/
â”œâ”€â”€ main.py
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ collector.py
â”‚   â””â”€â”€ parser.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ data_models.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ file_handler.py
â”‚   â””â”€â”€ analyzer.py
â”œâ”€â”€ data/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ CONTRIBUTIONS.md
â””â”€â”€ REPORT.md
```

## ðŸ“Œ Notes

- Target site: http://books.toscrape.com
- For testing purposes we scraped up to 2 pages (adjustable)
- Handles network and parsing errors gracefully